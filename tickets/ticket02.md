# Билет 2

## 2.1 Тренировочная, валидационная и тестовая выборка. Валидация и неравенство Хёфдинга. Кроссвалидация.
[Лекция](https://youtu.be/AySw5WqkEKo?feature=shared&t=4185)

У нас есть датасет $D$. Хотим научиться решать произвольную задачу, например классификации, на основе этого датасета, т.е. хотим как-то понимать качество полученного решения.

**Идея 1**: выделим 10-20% датасета (*тестовая выборка*), замаскируем ответ на тестовой выборке, и будем оптимизировать модель (e.g. оптимизировать гиперпараметры) на каждом этапе на основе результатов на этой тестовой выборке.

Проблема: если слишком много гиперпараметров, можем переобучить модель. Модель может обучиться отвечать исключительно хорошо на тестовой выборке, но в целом очень плохо по всем возможным входным данным.

**Идея 2**: Уберем тестовую выборку из датасета и выделим ещё 10-20% датасета (*валидационная выборка*). Будем оценивать модель во время обучения на валидационной выборке, а оценивать общее качество уже обученной модели уже непосредственно на тестовой выборке.

При этом зачастую производят *кроссвалидацию*: оставшиеся 80% датасета после удаления тестовой выборки делят на $n$ равных частей (*фолдов*), каждый из которых по очереди выбирается в качестве валидационной выборки, а остальные $n - 1$ формируют тренировочную выборку.

<img src='images/2_crossvalidation.png' align="center"></img>

### Неравенство Хёфдинга (вообще билет пиздецовый, поскольку по сути включает в себя ещё часть билета 12 и 13)

[Лекция](https://youtu.be/8RM6OYFjW1g?feature=shared&t=2528)

Вспоминаем определения:

* $N$ - размер датасета
* $h(x)$ - гипотеза 
* $f(x)$ - верная функция, её не знаем, хотим приблизить/угадать/оценить/смоделировать/прочее(необходимое подчеркнуть)
* $e(h, f)$ - функция ошибки. Зависит от класса задачи. Например, в задачах классификации $e(h(x_n), f(x_n)) = 1$ если класс $x_n$ в гипотезе ($h(x_n)$) совпал с ответом ($f(x_n)$), и $0$ иначе
* $ E_{in}(h) = \frac{1}{N}\sum_1^N e(h(x_n), f(x_n)) $ -- средняя ошибка гипотезы внутри датасета
* $ E_{out}(h) = \mathbb{E}_x\left[e(h(x), f(x))\right] $ -- средняя ошибка гипотезы на всех возможных датасетах. Обычно $E_{out}$ мы не знаем и хотим оценивать как-то математически.

Утверждение (*неравенство Хёфдинга*):

$$ \mathbb{P}\left[|E_{in}(h) - E_{out}(h)| > \varepsilon \right] \leqslant 2e^{-\varepsilon^2 N} $$

Без доказательства

Главный вывод: при больших $N$ можем с достаточно большой уверенностью что-то утверждать про качество классификатора.

Новое обозначение: $ |E_{in}(h) - E_{out}(h)| $ -- называется *Generalization error* (термин неустойчивый)

Теперь пусть у нас была не 1 гипотеза а $M$ гипотез. Тогда неравенство обращается в вид:

$$ \mathbb{P}\left[|E_{in}(h) - E_{out}(h)| > \varepsilon \right] \leqslant M2e^{-\varepsilon^2 N} $$

Тоже без доказательства.

*таймскип на билет 12.1 и 13.1*

Заметим, что при проверке на валидационной выборке неравенство имеет первый вид (поскольку на валидационной выборке мы проверяем ровно одну гипотезу в процессе обучения модели). То есть, при достаточно большой валидационной выборке мы умеем достаточно хорошо оценивать $E_{out}$.


## 2.2 Нейронные сети. Обратное распространение градиента.

[Лекция](https://youtu.be/kzhP504D4v8?feature=shared&t=2540)

Хотим обучать нейронную сеть, которая сложнее, чем один слой перцептронов.

Обозачения:

* $L$ - номер последнего слоя нейронной сети (нумерация слоев с 1)
* $L(w)$ - дифференцируемая функция потерь. Например, NLLL 
* $w^l_{jk}$ - вес между нейроном $j$ в слое $l - 1$ и нейроном $k$ в слое $l$
* $s^l_j = \sum_i w^l_{ij} x^{l-1}_i$ - входящий сигнал на нейрон $j$ слоя $l$
* $x^l_j = \sigma\left(\sum_i w^l_{ij}s^{l-1}_i\right)$ - исходящий сигнал из нейрона $j$ слоя $l$ после применения дифференцируемой функции активации $\sigma$. Устанавливаем начальные значения на первом слое как $x^1_j = x_j$

Общая задача, хотим научиться считать градиент $L$ для произвольных весов, то есть:

$$ \nabla L_{w^l_{ij}}(w) := \frac{\partial L(w)}{\partial w^l_{ij}} = \frac{\partial L(w)}{\partial s^l_j} \times \frac{\partial s^l_j}{\partial w^l_{ij}} $$

(замена переменной)

Заметим что, 
$$ \frac{\partial s^l_j}{\partial w^l_{ij}} = x^{l-1}_i $$

А левую кракозябру просто обозначим буквой: 
$$ \delta^l_j := \frac{\partial L(w)}{\partial s^l_j} $$

Суть: считаем все дельты начиная от последнего слоя к первому.

На последнем слое:

$$ \delta^L_i = \frac{\partial L(w)}{\partial s^L_i} $$

Более того, мы знаем, что $x^L_i = \sigma(s^L_i)$, а значит, мы можем явно посчитать $\delta^L_i$ (замена переменной)

А тогда мы умеем пересчитывать дельты на предыдущих слоях:

$$ \delta^{l - 1}_i = \frac{\partial L(w)}{\partial s^{l-1}_i} = \sum_j \frac{\partial L(w)}{\partial s^l_i} \times \frac{\partial s^l_j}{\partial x^{l-1}_i} \times \frac{\partial x^{l-1}_i}{\partial s^{l - 1}_i} = \sum_j \delta^l_j \times w^l_{ij} \times \sigma'(s^{l-1}_i) $$

(дважды заменили переменную: $ s^l_i \rightarrow x^{l-1}_i \rightarrow s^{l - 1}_i $)

Получаем алгоритм:

1. Инициализируем веса рандомно
2. Forward: просчитываем все $x$ и $s$
3. Backward: просчитываем $\delta$
4. $w^l_{ij} \leftarrow w^l_{ij} - \eta x^{l-1}_i\delta^l_j$
5. Повторяем с шага 2, пока не достигнем катарсиса