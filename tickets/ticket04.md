## 4.1. Кластеризация, метрики. Внешние метрики, homogeneity (purity). Внутренние метрики, silhouette, Dunn, Davies-Bouldin.

[Момент в лекции про метрики в кластеризации (YouTube)](https://youtu.be/mR3t3xN1J_I?si=Ww_9BlZ_pF4dfJUH)

[Момент в лекции про метрики в кластеризации (Google Диск)](https://drive.google.com/file/d/1LqQXsL31swEIHreAZL7ebXBRsjO-HeyA/view?usp=sharing&t=4503)


### Внешние метрики
Предполагают, что мы не решаем задачу кластеризации как 
она есть, а используем кластеризацию как способ получения 
новых знаний для решения каких-либо других задач. 
К примеру, мы можем получить новые фичи для решения задачи 
классификации (с помощью one-hot-encoding) с помощью кластеризации 
По большей части оцениваем как связаны классы с кластерами.

#### End metric (конечная метрика)

Настраиваем все параметры кластеризации так, чтобы максимизировать какое-то итоговое значение.
К примеру, делаем классификацию, по пути решаем задачу кластеризации для увеличения количества фич, 
пытаемся настроить параметры кластеризации так, 
чтобы получить наибольшее количество прибыли.
По сути, измеряем качество кластеризации по итоговой прибыли (или какому-либо еще значению), которое нужно максимизировать.

#### Homogeneity score (метрика гомогенности)

Метрика определяет долю максимального класса в кластере.

Значение метрики определяется по формуле: $$ \frac{1}{|D|} \sum_{i} max_{y} |x_i \in C_i, y_i = y| $$
Пояснение для картинки: каждый кружок соответствует кластеру и разбиение внутри кружочка - разбиение по классам.
![img.png](images/ticket04_1.png)

Для случая с картинки:

$$ \frac{10+30+20}{15+30+35} $$

Идеальный homogeneity-score - это 1, поскольку это будет означать что каждый кластер гомогенен и все его элементы принадлежат одному классу.
Чем больше кластеров - тем метрика лучше.

Самая плохой homogeneity-score при n классах - это $$ \frac{1}{n} $$

При анализе кластеризации стараются взять такие параметры, 
которые соответствуют точке перегиба homogeneity-score. Почему не в точке, где N кластеров и homogeneity-score равен 1? У нас каждая точка образует свой кластер, само собой homogeneity-score будет 1, но такая кластеризация не очень полезна.
![img.png](images/ticket04_2.png)

### Внутренние метрики

Пытаемся понять, какое разбиение на кластеры наилучшее, но не имеем какого-то конкретного известного разбиения на классы. 
Рассматриваем задачу кластеризации независимо, без привязки к классификации как во внешних метриках.

#### Silhouette coefficient

$$ s(x) = \frac{b(x)-a(x)}{max(a(x),b(x))} $$ где $a(x)$ - среднее расстояние от точки x до всех остальных точек в кластере, $b(x)$ - среднее расстояние от точки x до точек в соседнем, ближайшем кластере.

После подсчета $s(x)$ для каждой точки - считаем $s$ - среднее $s(x)$ для всех точек.

Хотим $s(x)$ - побольше, но происходит такая же проблема, что и с homogeneity-score - 1 будет достигаться при разделении всех точек на отдельные кластеры.

#### Dunn index

$$ D = \frac{min_{i\neq j}\rho(\mu_i,\mu_j)}{max_{x_i,x_j \in \mu}\rho(x_i,x_j)} $$

где $\mu$ - кластеры, $x_i$ - точки. 

Хотим максимизировать $D$ - хотим, чтобы расстояние внутри кластера было поменьше, а между кластерами - побольше.

Проблема Dunn index - в том, что $D$ учитывает в лучшем случае 3 кластера, для которых достигаются значения-экстремумы.

#### Davies-Bouldin index

$$ DB = \frac{1}{k} \sum_{i=1}^k max_{j \neq i} (\frac{\overline{\rho(\mu_i,x^i)}+\overline{\rho(\mu_j,x^j)}}{\rho(\mu_i,\mu_j)})$$

Здесь учитываем на все кластеры, но не на каждую точку.

$k$ - количество кластеров. Идем по всем кластерам, выбираем для каждого кластера другой, который максимизирует дробь. $\overline{\rho(\mu_j,x^j)}$ - среднее расстояние от точек кластера до центроида. 

$DB$ - хотим поменьше. 


